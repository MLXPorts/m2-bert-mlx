Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\\## Curated Notes - Supports NumPy‑like broadcasting across dimensions; ensure trailing axes align or expand via size‑1 axes. - Mixed dtypes follow promotion rules (e.g., int + float -> float). Cast explicitly if you need fixed precision: \\\\\\\`x.astype(mx.float32)\\\\\\\`. ### Examples \\\\\\\`\\\\\\\`\\\\\\\`python import mlx.core as mx # Vector + scalar v = mx.array(\\\\\\\[1, 2, 3\\\\\\\]) print(mx.add(v, 10)) # \\\\\\\[11, 12, 13\\\\\\\] # Broadcasting A = mx.ones((2, 3)) b = mx.array(\\\\\\\[10, 20, 30\\\\\\\]) print(mx.add(A, b)) # shape (2, 3) # Dtype promotion and explicit cast u8 = mx.array(\\\\\\\[1, 2, 3\\\\\\\], dtype=mx.uint8) f32 = mx.array(\\\\\\\[0.5, 0.5, 0.5\\\\\\\], dtype=mx.float32) mixed = mx.add(u8, f32) # float32 result by promotion fixed = mx.add(u8.astype(mx.float32), f32) \\\\\\\`\\\\\\\`\\\\\\\` \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/\\\_autosummary/mlx.core.add.rst "Download source file") - .pdf # mlx.core.add ## Contents \\\\- \\\[\\\`\\\`add()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.add) # mlx.core.add \\\`add\\\`(\\\\\\\*\\\`a\\\`\\\`:\\\` \\\`scalar\\\` \\\`\\\\\\\\|\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`b\\\`\\\`:\\\` \\\`scalar\\\` \\\`\\\\\\\\|\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`stream\\\`\\\`:\\\` \\\[\\\`None\\\`\\\](https://docs.python.org/3/library/constants.html#None "(in Python v3.13)") \\\`\\\\\\\\|\\\` \\\[\\\`Stream\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/stream\\\_class.html#mlx.core.Stream "mlx.core.Stream") \\\`\\\\\\\\|\\\` \\\[\\\`Device\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.Device.html#mlx.core.Device "mlx.core.Device") \\\`\\\\=\\\` \\\`None\\\`\\\\\\\*) → \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") Element-wise addition. Add two arrays with numpy-style broadcasting semantics. Either or both input arrays can also be scalars. Parameters: - \\\\\\\*\\\\\\\*a\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – Input array or scalar. - \\\\\\\*\\\\\\\*b\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – Input array or scalar. Returns: The sum of \\\`\\\\\\\`a\\\\\\\`\\\` and \\\`\\\\\\\`b\\\\\\\`\\\`. Return type: \\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.abs.html "previous page") previous mlx.core.abs \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.addmm.html "next page") next mlx.core.addmm Contents \\\\- \\\[\\\`\\\`add()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.add) By MLX Contributors © Copyright 2023, MLX Contributors.
