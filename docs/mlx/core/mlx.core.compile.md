Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/\\\_autosummary/mlx.core.compile.rst "Download source file") - .pdf # mlx.core.compile ## Contents \\\\- \\\[\\\`\\\`compile()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.compile) # mlx.core.compile \\\`compile\\\`(\\\\\\\*\\\`fun\\\`\\\`:\\\` \\\`Callable\\\`\\\\\\\*, \\\\\\\*\\\`inputs\\\`\\\`:\\\` \\\[\\\`object\\\`\\\](https://docs.python.org/3/library/functions.html#object "(in Python v3.13)") \\\`\\\\\\\\|\\\` \\\[\\\`None\\\`\\\](https://docs.python.org/3/library/constants.html#None "(in Python v3.13)") \\\`\\\\=\\\` \\\`None\\\`\\\\\\\*, \\\\\\\*\\\`outputs\\\`\\\`:\\\` \\\[\\\`object\\\`\\\](https://docs.python.org/3/library/functions.html#object "(in Python v3.13)") \\\`\\\\\\\\|\\\` \\\[\\\`None\\\`\\\](https://docs.python.org/3/library/constants.html#None "(in Python v3.13)") \\\`\\\\=\\\` \\\`None\\\`\\\\\\\*, \\\\\\\*\\\`shapeless\\\`\\\`:\\\` \\\[\\\`bool\\\`\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)") \\\`\\\\=\\\` \\\`False\\\`\\\\\\\*) → \\\`Callable\\\` Returns a compiled function which produces the same output as \\\`\\\\\\\`fun\\\\\\\`\\\`. Parameters: - \\\\\\\*\\\\\\\*fun\\\\\\\*\\\\\\\* (\\\\\\\*Callable\\\\\\\*) – A function which takes a variable number of \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") or trees of \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") and returns a variable number of \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") or trees of \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array"). - \\\\\\\*\\\\\\\*inputs\\\\\\\*\\\\\\\* (\\\[\\\*list\\\*\\\](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.13)") \\\\\\\*or\\\\\\\* \\\[\\\*dict\\\*\\\](https://docs.python.org/3/library/stdtypes.html#dict "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – These inputs will be captured during the function compilation along with the inputs to \\\`\\\\\\\`fun\\\\\\\`\\\`. The \\\`\\\\\\\`inputs\\\\\\\`\\\` can be a \\\[\\\`\\\`list\\\`\\\`\\\](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.13)") or a \\\[\\\`\\\`dict\\\`\\\`\\\](https://docs.python.org/3/library/stdtypes.html#dict "(in Python v3.13)") containing arbitrarily nested lists, dictionaries, or arrays. Leaf nodes that are not \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") are ignored. Default: \\\`\\\\\\\`None\\\\\\\`\\\` - \\\\\\\*\\\\\\\*outputs\\\\\\\*\\\\\\\* (\\\[\\\*list\\\*\\\](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.13)") \\\\\\\*or\\\\\\\* \\\[\\\*dict\\\*\\\](https://docs.python.org/3/library/stdtypes.html#dict "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – These outputs will be captured and updated in a compiled function. The \\\`\\\\\\\`outputs\\\\\\\`\\\` can be a \\\[\\\`\\\`list\\\`\\\`\\\](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.13)") or a \\\[\\\`\\\`dict\\\`\\\`\\\](https://docs.python.org/3/library/stdtypes.html#dict "(in Python v3.13)") containing arbitrarily nested lists, dictionaries, or arrays. Leaf nodes that are not \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") are ignored. Default: \\\`\\\\\\\`None\\\\\\\`\\\` - \\\\\\\*\\\\\\\*shapeless\\\\\\\*\\\\\\\* (\\\[\\\*bool\\\*\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – A function compiled with the \\\`\\\\\\\`shapeless\\\\\\\`\\\` option enabled will not be recompiled when the input shape changes. Not all functions can be compiled with \\\`\\\\\\\`shapeless\\\\\\\`\\\` enabled. Attempting to compile such functions with shapeless enabled will throw. Note, changing the number of dimensions or type of any input will result in a recompilation even with \\\`\\\\\\\`shapeless\\\\\\\`\\\` set to \\\`\\\\\\\`True\\\\\\\`\\\`. Default: \\\`\\\\\\\`False\\\\\\\`\\\` Returns: A compiled function which has the same input arguments as \\\`\\\\\\\`fun\\\\\\\`\\\` and returns the the same output(s). Return type: \\\\\\\*Callable\\\\\\\* ## MetalFaiss Notes — Real‑World Use and Benchmarks - Where compile helped most in practice: - SVD MLX step (Z = Aᵀ(A·V) then QR): compiling the one‑step function reduced repeated‑call overhead and fused MLX graphs. On a 512×256 matrix with k=32 and 3 iterations, we measured ~1.6× speedup (non‑compiled ≈0.036s → compiled ≈0.023s median). - Simple elementwise chains (e.g., GELU) fuse into one kernel; MLX docs show up to ~5× on large arrays. See also: function\\\\\\\_transforms.md (value\\\\\\\_and\\\\\\\_grad examples) and compile.md. - Kernel orchestration (custom Metal kernels): compiling a thin wrapper around gemm\\\\\\\_av→gemm\\\\\\\_at\\\\\\\_b is near parity (kernels dominate runtime), but still trims Python overhead when many bands or small kernels are dispatched. - Patterns we use: - Compile outer steps with stable shapes/dtypes; cache by (m,n,k,dtype,device). Avoid building/destroying compiled lambdas in loops. - Keep code MLX‑pure: use \\\\\\\`mx.square/mx.divide/mx.multiply/mx.where\\\\\\\`, no \\\\\\\`.item()/.numpy()/.tolist()\\\\\\\`; constants as MLX scalars. - Mixed CPU/GPU inside a compiled function works on Apple unified memory; assign ops to \\\\\\\`stream=mx.cpu\\\\\\\` or \\\\\\\`mx.gpu\\\\\\\`. MLX schedules cross‑device deps. See unified‑memory guidance in compile.md and transforms.md. ### Cross‑References - See also: - compile.md (Basics, shapeless mode, pitfalls) - function\\\\\\\_transforms.md (compose compile with grad/value\\\\\\\_and\\\\\\\_grad) - mlx.core.enable\\\\\\\_compile.md / mlx.core.disable\\\\\\\_compile.md - ../guides/MetalFaiss-Compile-Guide.md (project‑specific patterns, do/don’t list, and code snippets) \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.async\\\_eval.html "previous page") previous mlx.core.async\\\\\\\_eval \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.custom\\\_function.html "next page") next mlx.core.custom\\\\\\\_function Contents \\\\- \\\[\\\`\\\`compile()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.compile) By MLX Contributors © Copyright 2023, MLX Contributors.
