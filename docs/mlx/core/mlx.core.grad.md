Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/\\\_autosummary/mlx.core.grad.rst "Download source file") - .pdf # mlx.core.grad ## Contents \\\\- \\\[\\\`\\\`grad()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.grad) # mlx.core.grad \\\`grad\\\`(\\\\\\\*\\\`fun\\\`\\\`:\\\` \\\`Callable\\\`\\\\\\\*, \\\\\\\*\\\`argnums\\\`\\\`:\\\` \\\[\\\`int\\\`\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)") \\\`\\\\\\\\|\\\` \\\`Sequence\\\`\\\`\\\\\\\\\\\\\\\[\\\`\\\[\\\`int\\\`\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")\\\`\\\\\\\\\\\\\\\]\\\` \\\`\\\\\\\\|\\\` \\\[\\\`None\\\`\\\](https://docs.python.org/3/library/constants.html#None "(in Python v3.13)") \\\`\\\\=\\\` \\\`None\\\`\\\\\\\*, \\\\\\\*\\\`argnames\\\`\\\`:\\\` \\\[\\\`str\\\`\\\](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.13)") \\\`\\\\\\\\|\\\` \\\`Sequence\\\`\\\`\\\\\\\\\\\\\\\[\\\`\\\[\\\`str\\\`\\\](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.13)")\\\`\\\\\\\\\\\\\\\]\\\` \\\`\\\\=\\\` \\\`\\\\\\\\\\\\\\\[\\\\\\\\\\\\\\\]\\\`\\\\\\\*) → \\\`Callable\\\` Returns a function which computes the gradient of \\\`\\\\\\\`fun\\\\\\\`\\\`. Parameters: - \\\\\\\*\\\\\\\*fun\\\\\\\*\\\\\\\* (\\\\\\\*Callable\\\\\\\*) – A function which takes a variable number of \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") or trees of \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") and returns a scalar output \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array"). - \\\\\\\*\\\\\\\*argnums\\\\\\\*\\\\\\\* (\\\[\\\*int\\\*\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)") \\\\\\\*or\\\\\\\* \\\[\\\*list\\\*\\\](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.13)")\\\\\\\*(\\\\\\\*\\\[\\\*int\\\*\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")\\\\\\\*),\\\\\\\* \\\\\\\*optional\\\\\\\*) – Specify the index (or indices) of the positional arguments of \\\`\\\\\\\`fun\\\\\\\`\\\` to compute the gradient with respect to. If neither \\\`\\\\\\\`argnums\\\\\\\`\\\` nor \\\`\\\\\\\`argnames\\\\\\\`\\\` are provided \\\`\\\\\\\`argnums\\\\\\\`\\\` defaults to \\\`\\\\\\\`0\\\\\\\`\\\` indicating \\\`\\\\\\\`fun\\\\\\\`\\\`’s first argument. - \\\\\\\*\\\\\\\*argnames\\\\\\\*\\\\\\\* (\\\[\\\*str\\\*\\\](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.13)") \\\\\\\*or\\\\\\\* \\\[\\\*list\\\*\\\](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.13)")\\\\\\\*(\\\\\\\*\\\[\\\*str\\\*\\\](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.13)")\\\\\\\*),\\\\\\\* \\\\\\\*optional\\\\\\\*) – Specify keyword arguments of \\\`\\\\\\\`fun\\\\\\\`\\\` to compute gradients with respect to. It defaults to \\\\\\\\\\\\\\\[\\\\\\\\\\\\\\\] so no gradients for keyword arguments by default. Returns: A function which has the same input arguments as \\\`\\\\\\\`fun\\\\\\\`\\\` and returns the gradient(s). Return type: \\\\\\\*Callable\\\\\\\* \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.enable\\\_compile.html "previous page") previous mlx.core.enable\\\\\\\_compile \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.value\\\_and\\\_grad.html "next page") next mlx.core.value\\\\\\\_and\\\\\\\_grad Contents \\\\- \\\[\\\`\\\`grad()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.grad) By MLX Contributors © Copyright 2023, MLX Contributors.
