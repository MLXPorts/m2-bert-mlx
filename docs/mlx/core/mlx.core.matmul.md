Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\\## Curated Notes - Shapes: \\\\\\\`(..., m, k) @ (..., k, n) -> (..., m, n)\\\\\\\`, with leading dims broadcast. - No \\\\\\\`device=\\\\\\\` argument; device via default device or per‑op \\\\\\\`stream\\\\\\\`. - For quantized/int8 style matmul, prefer CPU unless your build advertises GPU support. ### Examples \\\\\\\`\\\\\\\`\\\\\\\`python import mlx.core as mx A = mx.random.normal((2, 3, 4)) B = mx.random.normal((2, 4, 5)) C = mx.matmul(A, B) # (2, 3, 5) # Broadcast batch dims Ab = mx.random.normal((1, 3, 4)) Bb = mx.random.normal((7, 4, 3)) Cb = mx.matmul(Ab, Bb) # (7, 3, 3) # CPU route C\\\\\\\_cpu = mx.matmul(A, B, stream=mx.cpu) \\\\\\\`\\\\\\\`\\\\\\\` \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/\\\_autosummary/mlx.core.matmul.rst "Download source file") - .pdf # mlx.core.matmul ## Contents \\\\- \\\[\\\`\\\`matmul()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.matmul) # mlx.core.matmul \\\`matmul\\\`(\\\\\\\*\\\`a\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`b\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`/\\\`\\\\\\\*, \\\\\\\*\\\`\\\\\\\\\\\\\\\*\\\`\\\\\\\*, \\\\\\\*\\\`stream\\\`\\\`:\\\` \\\[\\\`None\\\`\\\](https://docs.python.org/3/library/constants.html#None "(in Python v3.13)") \\\`\\\\\\\\|\\\` \\\[\\\`Stream\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/stream\\\_class.html#mlx.core.Stream "mlx.core.Stream") \\\`\\\\\\\\|\\\` \\\[\\\`Device\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.Device.html#mlx.core.Device "mlx.core.Device") \\\`\\\\=\\\` \\\`None\\\`\\\\\\\*) → \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") Matrix multiplication. Perform the (possibly batched) matrix multiplication of two arrays. This function supports broadcasting for arrays with more than two dimensions. - If the first array is 1-D then a 1 is prepended to its shape to make it a matrix. Similarly if the second array is 1-D then a 1 is appended to its shape to make it a matrix. In either case the singleton dimension is removed from the result. - A batched matrix multiplication is performed if the arrays have more than 2 dimensions. The matrix dimensions for the matrix product are the last two dimensions of each input. - All but the last two dimensions of each input are broadcast with one another using standard numpy-style broadcasting semantics. Parameters: - \\\\\\\*\\\\\\\*a\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – Input array or scalar. - \\\\\\\*\\\\\\\*b\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – Input array or scalar. Returns: The matrix product of \\\`\\\\\\\`a\\\\\\\`\\\` and \\\`\\\\\\\`b\\\\\\\`\\\`. Return type: \\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.logsumexp.html "previous page") previous mlx.core.logsumexp \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.max.html "next page") next mlx.core.max Contents \\\\- \\\[\\\`\\\`matmul()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.matmul) By MLX Contributors © Copyright 2023, MLX Contributors.
