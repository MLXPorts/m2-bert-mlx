Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/\\\_autosummary/mlx.core.logaddexp.rst "Download source file") - .pdf # mlx.core.logaddexp ## Contents \\\\- \\\[\\\`\\\`logaddexp()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.logaddexp) # mlx.core.logaddexp \\\`logaddexp\\\`(\\\\\\\*\\\`a\\\`\\\`:\\\` \\\`scalar\\\` \\\`\\\\\\\\|\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`b\\\`\\\`:\\\` \\\`scalar\\\` \\\`\\\\\\\\|\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`/\\\`\\\\\\\*, \\\\\\\*\\\`\\\\\\\\\\\\\\\*\\\`\\\\\\\*, \\\\\\\*\\\`stream\\\`\\\`:\\\` \\\[\\\`None\\\`\\\](https://docs.python.org/3/library/constants.html#None "(in Python v3.13)") \\\`\\\\\\\\|\\\` \\\[\\\`Stream\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/stream\\\_class.html#mlx.core.Stream "mlx.core.Stream") \\\`\\\\\\\\|\\\` \\\[\\\`Device\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.Device.html#mlx.core.Device "mlx.core.Device") \\\`\\\\=\\\` \\\`None\\\`\\\\\\\*) → \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") Element-wise log-add-exp. This is a numerically stable log-add-exp of two arrays with numpy-style broadcasting semantics. Either or both input arrays can also be scalars. The computation is is a numerically stable version of \\\`\\\\\\\`log(exp(a)\\\\\\\`\\\`\\\\\\\` \\\\\\\`\\\`\\\\\\\`+\\\\\\\`\\\`\\\\\\\` \\\\\\\`\\\`\\\\\\\`exp(b))\\\\\\\`\\\`. Parameters: - \\\\\\\*\\\\\\\*a\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – Input array or scalar. - \\\\\\\*\\\\\\\*b\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – Input array or scalar. Returns: The log-add-exp of \\\`\\\\\\\`a\\\\\\\`\\\` and \\\`\\\\\\\`b\\\\\\\`\\\`. Return type: \\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.log1p.html "previous page") previous mlx.core.log1p \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.logcumsumexp.html "next page") next mlx.core.logcumsumexp Contents \\\\- \\\[\\\`\\\`logaddexp()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.logaddexp) By MLX Contributors © Copyright 2023, MLX Contributors.
