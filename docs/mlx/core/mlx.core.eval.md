Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/\\\_autosummary/mlx.core.eval.rst "Download source file") - .pdf # mlx.core.eval ## Contents \\\\- \\\[\\\`\\\`eval()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.eval) # mlx.core.eval ## Curated Notes - Lazy by default: most MLX ops build a computation graph. Nothing runs until you force evaluation. - Triggers: \\\\\\\`mx.eval(x, y, ...)\\\\\\\`, scalar extraction via \\\\\\\`.item()\\\\\\\`, converting to NumPy, or using array values in Python control flow. - Why: deferring compute enables fusion and better scheduling; it also affects profiling (time moves to the first eval point). ### Examples \\\\\\\`\\\\\\\`\\\\\\\`python import mlx.core as mx # Build graph x = mx.random.normal((1024, 1024)) y = mx.tanh(x) + 0.1 \\\\\\\* x # Force compute when you actually need results mx.eval(y) # Scalars trigger eval via .item() loss = mx.mean(y\\\\\\\*\\\\\\\*2) print(loss.item()) # Trees are fine tree = {"u": mx.ones((2,2)), "v": mx.zeros((2,2))} mx.eval(tree) \\\\\\\`\\\\\\\`\\\\\\\` Tips: - Insert \\\\\\\`mx.eval(...)\\\\\\\` at debug/profiling boundaries; remove extra evals for production. - Keep differentiable code pure‑MLX to let the lazy optimizer do its work; avoid mixing NumPy mutations. \\\`eval\\\`(\\\\\\\*\\\`\\\\\\\\\\\\\\\*\\\`\\\`args\\\`\\\\\\\*) → \\\[\\\`None\\\`\\\](https://docs.python.org/3/library/constants.html#None "(in Python v3.13)") Evaluate an \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") or tree of \\\[\\\`\\\`array\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array"). Parameters: \\\\\\\*\\\\\\\*\\\\\\\\\\\\\\\*args\\\\\\\*\\\\\\\* (\\\\\\\*arrays\\\\\\\* \\\\\\\*or\\\\\\\* \\\\\\\*trees\\\\\\\* \\\\\\\*of\\\\\\\* \\\\\\\*arrays\\\\\\\*) – Each argument can be a single array or a tree of arrays. If a tree is given the nodes can be a Python \\\[\\\`\\\`list\\\`\\\`\\\](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.13)"), \\\[\\\`\\\`tuple\\\`\\\`\\\](https://docs.python.org/3/library/stdtypes.html#tuple "(in Python v3.13)") or \\\[\\\`\\\`dict\\\`\\\`\\\](https://docs.python.org/3/library/stdtypes.html#dict "(in Python v3.13)"). Leaves which are not arrays are ignored. \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/transforms.html "previous page") previous Transforms \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.async\\\_eval.html "next page") next mlx.core.async\\\\\\\_eval Contents \\\\- \\\[\\\`\\\`eval()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.core.eval) By MLX Contributors © Copyright 2023, MLX Contributors.
