Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/optimizers/\\\_autosummary/mlx.optimizers.MultiOptimizer.rst "Download source file") - .pdf # mlx.optimizers.MultiOptimizer ## Contents \\\\- \\\[\\\`\\\`MultiOptimizer\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.optimizers.MultiOptimizer) # mlx.optimizers.MultiOptimizer \\\\\\\*\\\`class\\\` \\\\\\\*\\\`MultiOptimizer\\\`(\\\\\\\*\\\`optimizers\\\`\\\\\\\*, \\\\\\\*\\\`filters\\\`\\\`:\\\` \\\[\\\`list\\\`\\\](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.13)") \\\`\\\\=\\\` \\\`\\\\\\\\\\\\\\\[\\\\\\\\\\\\\\\]\\\`\\\\\\\*) Wraps a list of optimizers with corresponding weight predicates/filters to make it easy to use different optimizers for different weights. The predicates take the full “path” of the weight and the weight itself and return True if it should be considered for this optimizer. The last optimizer in the list is a fallback optimizer and no predicate should be given for it. Parameters: - \\\\\\\*\\\\\\\*optimizers\\\\\\\*\\\\\\\* (\\\[\\\*list\\\*\\\](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.13)")\\\\\\\*\\\\\\\\\\\\\\\[\\\\\\\*\\\[\\\*Optimizer\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/optimizers/optimizer.html#mlx.optimizers.Optimizer "mlx.optimizers.Optimizer")\\\\\\\*\\\\\\\\\\\\\\\]\\\\\\\*) – A list of optimizers to delegate to - \\\\\\\*\\\\\\\*filters\\\\\\\*\\\\\\\* (\\\[\\\*list\\\*\\\](https://docs.python.org/3/library/stdtypes.html#list "(in Python v3.13)")\\\\\\\*\\\\\\\\\\\\\\\[Callable\\\\\\\\\\\\\\\[\\\\\\\\\\\\\\\[\\\\\\\*\\\[\\\*str\\\*\\\](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*\\\\\\\\\\\\\\\],\\\\\\\* \\\[\\\*bool\\\*\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)")\\\\\\\*\\\\\\\\\\\\\\\]\\\\\\\*) – A list of predicates that should be one less than the provided optimizers. Methods | | | |----|----| | \\\`\\\\\\\`\\\\\\\_\\\\\\\_init\\\\\\\_\\\\\\\_\\\\\\\`\\\`(optimizers\\\\\\\\\\\\\\\[, filters\\\\\\\\\\\\\\\]) | | | \\\`\\\\\\\`apply\\\\\\\_gradients\\\\\\\`\\\`(gradients, parameters) | Apply the gradients to the parameters and return the updated parameters. | | \\\`\\\\\\\`init\\\\\\\`\\\`(parameters) | Initialize the optimizer's state | \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/optimizers/\\\_autosummary/mlx.optimizers.Lion.html "previous page") previous mlx.optimizers.Lion \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/optimizers/schedulers.html "next page") next Schedulers Contents \\\\- \\\[\\\`\\\`MultiOptimizer\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.optimizers.MultiOptimizer) By MLX Contributors © Copyright 2023, MLX Contributors.
