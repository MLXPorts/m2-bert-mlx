Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/nn/\\\_autosummary/mlx.nn.Module.train.rst "Download source file") - .pdf # mlx.nn.Module.train ## Contents \\\\- \\\[\\\`\\\`Module.train()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.Module.train) # mlx.nn.Module.train \\\`Module.\\\`\\\`train\\\`(\\\\\\\*\\\`mode\\\`\\\`:\\\` \\\[\\\`bool\\\`\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)") \\\`\\\\=\\\` \\\`True\\\`\\\\\\\*) → \\\[\\\`Module\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/nn/module.html#mlx.nn.Module "mlx.nn.layers.base.Module") Set the model in or out of training mode. Training mode only applies to certain layers. For example \\\[\\\`\\\`Dropout\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.Dropout.html#mlx.nn.Dropout "mlx.nn.Dropout") applies a random mask in training mode, but is the identity in evaluation mode. Parameters: \\\\\\\*\\\\\\\*mode\\\\\\\*\\\\\\\* (\\\[\\\*bool\\\*\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)")) – Indicate if the model should be in training or evaluation mode. Default: \\\`\\\\\\\`True\\\\\\\`\\\`. Returns: The module instance after updating the training mode. \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.Module.set\\\_dtype.html "previous page") previous mlx.nn.Module.set\\\\\\\_dtype \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.Module.trainable\\\_parameters.html "next page") next mlx.nn.Module.trainable\\\\\\\_parameters Contents \\\\- \\\[\\\`\\\`Module.train()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.Module.train) By MLX Contributors © Copyright 2023, MLX Contributors.
