Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/nn/\\\_autosummary/mlx.nn.Mish.rst "Download source file") - .pdf # mlx.nn.Mish ## Contents \\\\- \\\[\\\`\\\`Mish\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.Mish) # mlx.nn.Mish \\\\\\\*\\\`class\\\` \\\\\\\*\\\`Mish\\\` Applies the Mish function, element-wise. Reference: \\\[https://arxiv.org/abs/1908.08681\\\](https://arxiv.org/abs/1908.08681) \\\\\\\\\\\\\\\\\\\\\\\\text{Mish}(x) = x \\\\\\\\\\\\\\\* \\\\\\\\text{Tanh}(\\\\\\\\text{Softplus}(x))\\\\\\\\\\\\\\\\ Methods \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.MaxPool3d.html "previous page") previous mlx.nn.MaxPool3d \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.MultiHeadAttention.html "next page") next mlx.nn.MultiHeadAttention Contents \\\\- \\\[\\\`\\\`Mish\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.Mish) By MLX Contributors Â© Copyright 2023, MLX Contributors.
