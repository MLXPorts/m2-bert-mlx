Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/nn/\\\_autosummary/mlx.nn.RNN.rst "Download source file") - .pdf # mlx.nn.RNN ## Contents \\\\- \\\[\\\`\\\`RNN\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.RNN) # mlx.nn.RNN \\\\\\\*\\\`class\\\` \\\\\\\*\\\`RNN\\\`(\\\\\\\*\\\`input\\\\\\\_size\\\`\\\`:\\\` \\\[\\\`int\\\`\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")\\\\\\\*, \\\\\\\*\\\`hidden\\\\\\\_size\\\`\\\`:\\\` \\\[\\\`int\\\`\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")\\\\\\\*, \\\\\\\*\\\`bias\\\`\\\`:\\\` \\\[\\\`bool\\\`\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)") \\\`\\\\=\\\` \\\`True\\\`\\\\\\\*, \\\\\\\*\\\`nonlinearity\\\`\\\`:\\\` \\\[\\\`Callable\\\`\\\](https://docs.python.org/3/library/typing.html#typing.Callable "(in Python v3.13)") \\\`\\\\\\\\|\\\` \\\[\\\`None\\\`\\\](https://docs.python.org/3/library/constants.html#None "(in Python v3.13)") \\\`\\\\=\\\` \\\`None\\\`\\\\\\\*) An Elman recurrent layer. The input is a sequence of shape \\\`\\\\\\\`NLD\\\\\\\`\\\` or \\\`\\\\\\\`LD\\\\\\\`\\\` where: - \\\`\\\\\\\`N\\\\\\\`\\\` is the optional batch dimension - \\\`\\\\\\\`L\\\\\\\`\\\` is the sequence length - \\\`\\\\\\\`D\\\\\\\`\\\` is the input’s feature dimension Concretely, for each element along the sequence length axis, this layer applies the function: \\\\\\\\\\\\\\\\h\\\\\\\\\\\\\\\_{t + 1} = \\\\\\\\text{tanh} (W\\\\\\\\\\\\\\\_{ih}x\\\\\\\_t + W\\\\\\\\\\\\\\\_{hh}h\\\\\\\_t + b)\\\\\\\\\\\\\\\\ The hidden state \\\\\\\\\\\\\\\\h\\\\\\\\\\\\\\\\ has shape \\\`\\\\\\\`NH\\\\\\\`\\\` or \\\`\\\\\\\`H\\\\\\\`\\\`, depending on whether the input is batched or not. Returns the hidden state at each time step, of shape \\\`\\\\\\\`NLH\\\\\\\`\\\` or \\\`\\\\\\\`LH\\\\\\\`\\\`. Parameters: - \\\\\\\*\\\\\\\*input\\\\\\\_size\\\\\\\*\\\\\\\* (\\\[\\\*int\\\*\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")) – Dimension of the input, \\\`\\\\\\\`D\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*hidden\\\\\\\_size\\\\\\\*\\\\\\\* (\\\[\\\*int\\\*\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")) – Dimension of the hidden state, \\\`\\\\\\\`H\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*bias\\\\\\\*\\\\\\\* (\\\[\\\*bool\\\*\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Whether to use a bias. Default: \\\`\\\\\\\`True\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*nonlinearity\\\\\\\*\\\\\\\* (\\\\\\\*callable,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Non-linearity to use. If \\\`\\\\\\\`None\\\\\\\`\\\`, then func:tanh is used. Default: \\\`\\\\\\\`None\\\\\\\`\\\`. Methods \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.ReLU6.html "previous page") previous mlx.nn.ReLU6 \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.RoPE.html "next page") next mlx.nn.RoPE Contents \\\\- \\\[\\\`\\\`RNN\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.RNN) By MLX Contributors © Copyright 2023, MLX Contributors.
