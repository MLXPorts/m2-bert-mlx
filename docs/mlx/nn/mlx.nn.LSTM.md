Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/nn/\\\_autosummary/mlx.nn.LSTM.rst "Download source file") - .pdf # mlx.nn.LSTM ## Contents \\\\- \\\[\\\`\\\`LSTM\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.LSTM) # mlx.nn.LSTM \\\\\\\*\\\`class\\\` \\\\\\\*\\\`LSTM\\\`(\\\\\\\*\\\`input\\\\\\\_size\\\`\\\`:\\\` \\\[\\\`int\\\`\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")\\\\\\\*, \\\\\\\*\\\`hidden\\\\\\\_size\\\`\\\`:\\\` \\\[\\\`int\\\`\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")\\\\\\\*, \\\\\\\*\\\`bias\\\`\\\`:\\\` \\\[\\\`bool\\\`\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)") \\\`\\\\=\\\` \\\`True\\\`\\\\\\\*) An LSTM recurrent layer. The input has shape \\\`\\\\\\\`NLD\\\\\\\`\\\` or \\\`\\\\\\\`LD\\\\\\\`\\\` where: - \\\`\\\\\\\`N\\\\\\\`\\\` is the optional batch dimension - \\\`\\\\\\\`L\\\\\\\`\\\` is the sequence length - \\\`\\\\\\\`D\\\\\\\`\\\` is the input’s feature dimension Concretely, for each element of the sequence, this layer computes: \\\\\\\\\\\\\\\\\\\\\\\\begin{split}\\\\\\\\begin{aligned} i\\\\\\\_t &= \\\\\\\\sigma (W\\\\\\\\\\\\\\\_{xi}x\\\\\\\_t + W\\\\\\\\\\\\\\\_{hi}h\\\\\\\_t + b\\\\\\\\\\\\\\\_{i}) \\\\\\\\\\\\\\\\ f\\\\\\\_t &= \\\\\\\\sigma (W\\\\\\\\\\\\\\\_{xf}x\\\\\\\_t + W\\\\\\\\\\\\\\\_{hf}h\\\\\\\_t + b\\\\\\\\\\\\\\\_{f}) \\\\\\\\\\\\\\\\ g\\\\\\\_t &= \\\\\\\\text{tanh} (W\\\\\\\\\\\\\\\_{xg}x\\\\\\\_t + W\\\\\\\\\\\\\\\_{hg}h\\\\\\\_t + b\\\\\\\\\\\\\\\_{g}) \\\\\\\\\\\\\\\\ o\\\\\\\_t &= \\\\\\\\sigma (W\\\\\\\\\\\\\\\_{xo}x\\\\\\\_t + W\\\\\\\\\\\\\\\_{ho}h\\\\\\\_t + b\\\\\\\\\\\\\\\_{o}) \\\\\\\\\\\\\\\\ c\\\\\\\\\\\\\\\_{t + 1} &= f\\\\\\\_t \\\\\\\\odot c\\\\\\\_t + i\\\\\\\_t \\\\\\\\odot g\\\\\\\_t \\\\\\\\\\\\\\\\ h\\\\\\\\\\\\\\\_{t + 1} &= o\\\\\\\_t \\\\\\\\text{tanh}(c\\\\\\\\\\\\\\\_{t + 1}) \\\\\\\\end{aligned}\\\\\\\\end{split}\\\\\\\\\\\\\\\\ The hidden state \\\\\\\\\\\\\\\\h\\\\\\\\\\\\\\\\ and cell state \\\\\\\\\\\\\\\\c\\\\\\\\\\\\\\\\ have shape \\\`\\\\\\\`NH\\\\\\\`\\\` or \\\`\\\\\\\`H\\\\\\\`\\\`, depending on whether the input is batched or not. The layer returns two arrays, the hidden state and the cell state at each time step, both of shape \\\`\\\\\\\`NLH\\\\\\\`\\\` or \\\`\\\\\\\`LH\\\\\\\`\\\`. Parameters: - \\\\\\\*\\\\\\\*input\\\\\\\_size\\\\\\\*\\\\\\\* (\\\[\\\*int\\\*\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")) – Dimension of the input, \\\`\\\\\\\`D\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*hidden\\\\\\\_size\\\\\\\*\\\\\\\* (\\\[\\\*int\\\*\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")) – Dimension of the hidden state, \\\`\\\\\\\`H\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*bias\\\\\\\*\\\\\\\* (\\\[\\\*bool\\\*\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)")) – Whether to use biases or not. Default: \\\`\\\\\\\`True\\\\\\\`\\\`. Methods \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.LogSoftmax.html "previous page") previous mlx.nn.LogSoftmax \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.MaxPool1d.html "next page") next mlx.nn.MaxPool1d Contents \\\\- \\\[\\\`\\\`LSTM\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.LSTM) By MLX Contributors © Copyright 2023, MLX Contributors.
