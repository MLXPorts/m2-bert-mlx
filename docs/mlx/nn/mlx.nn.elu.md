Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/nn/\\\_autosummary/mlx.nn.ELU.rst "Download source file") - .pdf # mlx.nn.ELU ## Contents \\\\- \\\[\\\`\\\`ELU\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.ELU) # mlx.nn.ELU \\\\\\\*\\\`class\\\` \\\\\\\*\\\`ELU\\\`(\\\\\\\*\\\`alpha\\\`\\\`\\\\=\\\`\\\`1.0\\\`\\\\\\\*) Applies the Exponential Linear Unit. Simply \\\`\\\\\\\`mx.where(x\\\\\\\`\\\`\\\\\\\` \\\\\\\`\\\`\\\\\\\`>\\\\\\\`\\\`\\\\\\\` \\\\\\\`\\\`\\\\\\\`0,\\\\\\\`\\\`\\\\\\\` \\\\\\\`\\\`\\\\\\\`x,\\\\\\\`\\\`\\\\\\\` \\\\\\\`\\\`\\\\\\\`alpha\\\\\\\`\\\`\\\\\\\` \\\\\\\`\\\`\\\\\\\`\\\\\\\*\\\\\\\`\\\`\\\\\\\` \\\\\\\`\\\`\\\\\\\`(mx.exp(x)\\\\\\\`\\\`\\\\\\\` \\\\\\\`\\\`\\\\\\\`-\\\\\\\`\\\`\\\\\\\` \\\\\\\`\\\`\\\\\\\`1))\\\\\\\`\\\`. See \\\[\\\`\\\`elu()\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary\\\_functions/mlx.nn.elu.html#mlx.nn.elu "mlx.nn.elu") for the functional equivalent. Parameters: \\\\\\\*\\\\\\\*alpha\\\\\\\*\\\\\\\* – the \\\\\\\\\\\\\\\\\\\\\\\\alpha\\\\\\\\\\\\\\\\ value for the ELU formulation. Default: \\\`\\\\\\\`1.0\\\\\\\`\\\` Methods \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.Embedding.html "previous page") previous mlx.nn.Embedding \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.GELU.html "next page") next mlx.nn.GELU Contents \\\\- \\\[\\\`\\\`ELU\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.ELU) By MLX Contributors © Copyright 2023, MLX Contributors.
