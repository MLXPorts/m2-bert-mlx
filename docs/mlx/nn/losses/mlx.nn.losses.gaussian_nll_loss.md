Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/nn/\\\_autosummary\\\_functions/mlx.nn.losses.gaussian\\\_nll\\\_loss.rst "Download source file") - .pdf # mlx.nn.losses.gaussian\\\\\\\_nll\\\\\\\_loss ## Contents \\\\- \\\[\\\`\\\`gaussian\\\_nll\\\_loss\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.losses.gaussian\\\_nll\\\_loss) # mlx.nn.losses.gaussian\\\\\\\_nll\\\\\\\_loss \\\\\\\*\\\`class\\\` \\\\\\\*\\\`gaussian\\\\\\\_nll\\\\\\\_loss\\\`(\\\\\\\*\\\`inputs\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`targets\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`vars\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`full\\\`\\\`:\\\` \\\[\\\`bool\\\`\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)") \\\`\\\\=\\\` \\\`False\\\`\\\\\\\*, \\\\\\\*\\\`eps\\\`\\\`:\\\` \\\[\\\`float\\\`\\\](https://docs.python.org/3/library/functions.html#float "(in Python v3.13)") \\\`\\\\=\\\` \\\`1e-06\\\`\\\\\\\*, \\\\\\\*\\\`reduction\\\`\\\`:\\\` \\\[\\\`Literal\\\`\\\](https://docs.python.org/3/library/typing.html#typing.Literal "(in Python v3.13)")\\\`\\\\\\\\\\\\\\\[\\\`\\\`'none'\\\`\\\`,\\\` \\\`'mean'\\\`\\\`,\\\` \\\`'sum'\\\`\\\`\\\\\\\\\\\\\\\]\\\` \\\`\\\\=\\\` \\\`'mean'\\\`\\\\\\\*) Computes the negative log likelihood loss for a Gaussian distribution. The loss is given by: \\\\\\\\\\\\\\\\\\\\\\\\frac{1}{2}\\\\\\\\left(\\\\\\\\log\\\\\\\\left(\\\\\\\\max\\\\\\\\left(\\\\\\\\text{vars}, \\\\\\\\\\\\\\\\ \\\\\\\\epsilon\\\\\\\\right)\\\\\\\\right) + \\\\\\\\frac{\\\\\\\\left(\\\\\\\\text{inputs} - \\\\\\\\text{targets} \\\\\\\\right)^2} {\\\\\\\\max\\\\\\\\left(\\\\\\\\text{vars}, \\\\\\\\\\\\\\\\ \\\\\\\\epsilon \\\\\\\\right)}\\\\\\\\right) + \\\\\\\\text{const.}\\\\\\\\\\\\\\\\ where \\\`\\\\\\\`inputs\\\\\\\`\\\` are the predicted means and \\\`\\\\\\\`vars\\\\\\\`\\\` are the the predicted variances. Parameters: - \\\\\\\*\\\\\\\*inputs\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – The predicted expectation of the Gaussian distribution. - \\\\\\\*\\\\\\\*targets\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – The target values (samples from the Gaussian distribution). - \\\\\\\*\\\\\\\*vars\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – The predicted variance of the Gaussian distribution. - \\\\\\\*\\\\\\\*full\\\\\\\*\\\\\\\* (\\\[\\\*bool\\\*\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Whether to include the constant term in the loss calculation. Default: \\\`\\\\\\\`False\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*eps\\\\\\\*\\\\\\\* (\\\[\\\*float\\\*\\\](https://docs.python.org/3/library/functions.html#float "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Small positive constant for numerical stability. Default: \\\`\\\\\\\`1e-6\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*reduction\\\\\\\*\\\\\\\* (\\\[\\\*str\\\*\\\](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Specifies the reduction to apply to the output: \\\`\\\\\\\`'none'\\\\\\\`\\\` \\\\\\\\| \\\`\\\\\\\`'mean'\\\\\\\`\\\` \\\\\\\\| \\\`\\\\\\\`'sum'\\\\\\\`\\\`. Default: \\\`\\\\\\\`'none'\\\\\\\`\\\`. Returns: The Gaussian NLL loss. Return type: \\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary\\\_functions/mlx.nn.losses.cross\\\_entropy.html "previous page") previous mlx.nn.losses.cross\\\\\\\_entropy \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary\\\_functions/mlx.nn.losses.hinge\\\_loss.html "next page") next mlx.nn.losses.hinge\\\\\\\_loss Contents \\\\- \\\[\\\`\\\`gaussian\\\_nll\\\_loss\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.losses.gaussian\\\_nll\\\_loss) By MLX Contributors © Copyright 2023, MLX Contributors.
