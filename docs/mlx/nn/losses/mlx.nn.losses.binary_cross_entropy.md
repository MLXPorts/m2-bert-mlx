Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/nn/\\\_autosummary\\\_functions/mlx.nn.losses.binary\\\_cross\\\_entropy.rst "Download source file") - .pdf # mlx.nn.losses.binary\\\\\\\_cross\\\\\\\_entropy ## Contents \\\\- \\\[\\\`\\\`binary\\\_cross\\\_entropy\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.losses.binary\\\_cross\\\_entropy) # mlx.nn.losses.binary\\\\\\\_cross\\\\\\\_entropy \\\\\\\*\\\`class\\\` \\\\\\\*\\\`binary\\\\\\\_cross\\\\\\\_entropy\\\`(\\\\\\\*\\\`inputs\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`targets\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`weights\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") \\\`\\\\\\\\|\\\` \\\[\\\`None\\\`\\\](https://docs.python.org/3/library/constants.html#None "(in Python v3.13)") \\\`\\\\=\\\` \\\`None\\\`\\\\\\\*, \\\\\\\*\\\`with\\\\\\\_logits\\\`\\\`:\\\` \\\[\\\`bool\\\`\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)") \\\`\\\\=\\\` \\\`True\\\`\\\\\\\*, \\\\\\\*\\\`reduction\\\`\\\`:\\\` \\\[\\\`Literal\\\`\\\](https://docs.python.org/3/library/typing.html#typing.Literal "(in Python v3.13)")\\\`\\\\\\\\\\\\\\\[\\\`\\\`'none'\\\`\\\`,\\\` \\\`'mean'\\\`\\\`,\\\` \\\`'sum'\\\`\\\`\\\\\\\\\\\\\\\]\\\` \\\`\\\\=\\\` \\\`'mean'\\\`\\\\\\\*) Computes the binary cross entropy loss. By default, this function takes the pre-sigmoid logits, which results in a faster and more precise loss. For improved numerical stability when \\\`\\\\\\\`with\\\\\\\_logits=False\\\\\\\`\\\`, the loss calculation clips the input probabilities (in log-space) to a minimum value of \\\`\\\\\\\`-100\\\\\\\`\\\`. Parameters: - \\\\\\\*\\\\\\\*inputs\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – The predicted values. If \\\`\\\\\\\`with\\\\\\\_logits\\\\\\\`\\\` is \\\`\\\\\\\`True\\\\\\\`\\\`, then \\\`\\\\\\\`inputs\\\\\\\`\\\` are unnormalized logits. Otherwise, \\\`\\\\\\\`inputs\\\\\\\`\\\` are probabilities. - \\\\\\\*\\\\\\\*targets\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – The binary target values in {0, 1}. - \\\\\\\*\\\\\\\*with\\\\\\\_logits\\\\\\\*\\\\\\\* (\\\[\\\*bool\\\*\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Whether \\\`\\\\\\\`inputs\\\\\\\`\\\` are logits. Default: \\\`\\\\\\\`True\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*weights\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Optional weights for each target. Default: \\\`\\\\\\\`None\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*reduction\\\\\\\*\\\\\\\* (\\\[\\\*str\\\*\\\](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Specifies the reduction to apply to the output: \\\`\\\\\\\`'none'\\\\\\\`\\\` \\\\\\\\| \\\`\\\\\\\`'mean'\\\\\\\`\\\` \\\\\\\\| \\\`\\\\\\\`'sum'\\\\\\\`\\\`. Default: \\\`\\\\\\\`'mean'\\\\\\\`\\\`. Returns: The computed binary cross entropy loss. Return type: \\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") Examples \\\\>>> import mlx.core as mx >>> import mlx.nn as nn \\\\>>> logits = mx.array(\\\\\\\[0.105361, 0.223144, 1.20397, 0.916291\\\\\\\]) >>> targets = mx.array(\\\\\\\[0, 0, 1, 1\\\\\\\]) >>> loss = nn.losses.binary\\\\\\\_cross\\\\\\\_entropy(logits, targets, reduction="mean") >>> loss array(0.539245, dtype=float32) \\\\>>> probs = mx.array(\\\\\\\[0.1, 0.1, 0.4, 0.4\\\\\\\]) >>> targets = mx.array(\\\\\\\[0, 0, 1, 1\\\\\\\]) >>> loss = nn.losses.binary\\\\\\\_cross\\\\\\\_entropy(probs, targets, with\\\\\\\_logits=False, reduction="mean") >>> loss array(0.510826, dtype=float32) \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/losses.html "previous page") previous Loss Functions \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary\\\_functions/mlx.nn.losses.cosine\\\_similarity\\\_loss.html "next page") next mlx.nn.losses.cosine\\\\\\\_similarity\\\\\\\_loss Contents \\\\- \\\[\\\`\\\`binary\\\_cross\\\_entropy\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.losses.binary\\\_cross\\\_entropy) By MLX Contributors © Copyright 2023, MLX Contributors.
