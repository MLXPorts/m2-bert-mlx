Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/nn/\\\_autosummary\\\_functions/mlx.nn.losses.cross\\\_entropy.rst "Download source file") - .pdf # mlx.nn.losses.cross\\\\\\\_entropy ## Contents \\\\- \\\[\\\`\\\`cross\\\_entropy\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.losses.cross\\\_entropy) # mlx.nn.losses.cross\\\\\\\_entropy \\\\\\\*\\\`class\\\` \\\\\\\*\\\`cross\\\\\\\_entropy\\\`(\\\\\\\*\\\`logits\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`targets\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*, \\\\\\\*\\\`weights\\\`\\\`:\\\` \\\[\\\`array\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") \\\`\\\\\\\\|\\\` \\\[\\\`None\\\`\\\](https://docs.python.org/3/library/constants.html#None "(in Python v3.13)") \\\`\\\\=\\\` \\\`None\\\`\\\\\\\*, \\\\\\\*\\\`axis\\\`\\\`:\\\` \\\[\\\`int\\\`\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)") \\\`\\\\=\\\` \\\`\\\\-1\\\`\\\\\\\*, \\\\\\\*\\\`label\\\\\\\_smoothing\\\`\\\`:\\\` \\\[\\\`float\\\`\\\](https://docs.python.org/3/library/functions.html#float "(in Python v3.13)") \\\`\\\\=\\\` \\\`0.0\\\`\\\\\\\*, \\\\\\\*\\\`reduction\\\`\\\`:\\\` \\\[\\\`Literal\\\`\\\](https://docs.python.org/3/library/typing.html#typing.Literal "(in Python v3.13)")\\\`\\\\\\\\\\\\\\\[\\\`\\\`'none'\\\`\\\`,\\\` \\\`'mean'\\\`\\\`,\\\` \\\`'sum'\\\`\\\`\\\\\\\\\\\\\\\]\\\` \\\`\\\\=\\\` \\\`'none'\\\`\\\\\\\*) Computes the cross entropy loss. Parameters: - \\\\\\\*\\\\\\\*logits\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – The unnormalized logits. - \\\\\\\*\\\\\\\*targets\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")) – The ground truth values. These can be class indices or probabilities for each class. If the \\\`\\\\\\\`targets\\\\\\\`\\\` are class indices, then \\\`\\\\\\\`targets\\\\\\\`\\\` shape should match the \\\`\\\\\\\`logits\\\\\\\`\\\` shape with the \\\`\\\\\\\`axis\\\\\\\`\\\` dimension removed. If the \\\`\\\\\\\`targets\\\\\\\`\\\` are probabilities (or one-hot encoded), then the \\\`\\\\\\\`targets\\\\\\\`\\\` shape should be the same as the \\\`\\\\\\\`logits\\\\\\\`\\\` shape. - \\\\\\\*\\\\\\\*weights\\\\\\\*\\\\\\\* (\\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Optional weights for each target. Default: \\\`\\\\\\\`None\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*axis\\\\\\\*\\\\\\\* (\\\[\\\*int\\\*\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – The axis over which to compute softmax. Default: \\\`\\\\\\\`-1\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*label\\\\\\\_smoothing\\\\\\\*\\\\\\\* (\\\[\\\*float\\\*\\\](https://docs.python.org/3/library/functions.html#float "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Label smoothing factor. Default: \\\`\\\\\\\`0\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*reduction\\\\\\\*\\\\\\\* (\\\[\\\*str\\\*\\\](https://docs.python.org/3/library/stdtypes.html#str "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – Specifies the reduction to apply to the output: \\\`\\\\\\\`'none'\\\\\\\`\\\` \\\\\\\\| \\\`\\\\\\\`'mean'\\\\\\\`\\\` \\\\\\\\| \\\`\\\\\\\`'sum'\\\\\\\`\\\`. Default: \\\`\\\\\\\`'none'\\\\\\\`\\\`. Returns: The computed cross entropy loss. Return type: \\\[\\\*array\\\*\\\](https://ml-explore.github.io/mlx/build/html/python/\\\_autosummary/mlx.core.array.html#mlx.core.array "mlx.core.array") Examples \\\\>>> import mlx.core as mx >>> import mlx.nn as nn >>> >>> # Class indices as targets >>> logits = mx.array(\\\\\\\[\\\\\\\[2.0, -1.0\\\\\\\], \\\\\\\[-1.0, 2.0\\\\\\\]\\\\\\\]) >>> targets = mx.array(\\\\\\\[0, 1\\\\\\\]) >>> nn.losses.cross\\\\\\\_entropy(logits, targets) array(\\\\\\\[0.0485873, 0.0485873\\\\\\\], dtype=float32) >>> >>> # Probabilities (or one-hot vectors) as targets >>> logits = mx.array(\\\\\\\[\\\\\\\[2.0, -1.0\\\\\\\], \\\\\\\[-1.0, 2.0\\\\\\\]\\\\\\\]) >>> targets = mx.array(\\\\\\\[\\\\\\\[0.9, 0.1\\\\\\\], \\\\\\\[0.1, 0.9\\\\\\\]\\\\\\\]) >>> nn.losses.cross\\\\\\\_entropy(logits, targets) array(\\\\\\\[0.348587, 0.348587\\\\\\\], dtype=float32) \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary\\\_functions/mlx.nn.losses.cosine\\\_similarity\\\_loss.html "previous page") previous mlx.nn.losses.cosine\\\\\\\_similarity\\\\\\\_loss \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary\\\_functions/mlx.nn.losses.gaussian\\\_nll\\\_loss.html "next page") next mlx.nn.losses.gaussian\\\\\\\_nll\\\\\\\_loss Contents \\\\- \\\[\\\`\\\`cross\\\_entropy\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.losses.cross\\\_entropy) By MLX Contributors © Copyright 2023, MLX Contributors.
