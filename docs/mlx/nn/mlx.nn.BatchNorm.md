Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/nn/\\\_autosummary/mlx.nn.BatchNorm.rst "Download source file") - .pdf # mlx.nn.BatchNorm ## Contents \\\\- \\\[\\\`\\\`BatchNorm\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.BatchNorm) # mlx.nn.BatchNorm \\\\\\\*\\\`class\\\` \\\\\\\*\\\`BatchNorm\\\`(\\\\\\\*\\\`num\\\\\\\_features\\\`\\\`:\\\` \\\[\\\`int\\\`\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")\\\\\\\*, \\\\\\\*\\\`eps\\\`\\\`:\\\` \\\[\\\`float\\\`\\\](https://docs.python.org/3/library/functions.html#float "(in Python v3.13)") \\\`\\\\=\\\` \\\`1e-05\\\`\\\\\\\*, \\\\\\\*\\\`momentum\\\`\\\`:\\\` \\\[\\\`float\\\`\\\](https://docs.python.org/3/library/functions.html#float "(in Python v3.13)") \\\`\\\\=\\\` \\\`0.1\\\`\\\\\\\*, \\\\\\\*\\\`affine\\\`\\\`:\\\` \\\[\\\`bool\\\`\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)") \\\`\\\\=\\\` \\\`True\\\`\\\\\\\*, \\\\\\\*\\\`track\\\\\\\_running\\\\\\\_stats\\\`\\\`:\\\` \\\[\\\`bool\\\`\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)") \\\`\\\\=\\\` \\\`True\\\`\\\\\\\*) Applies Batch Normalization over a 2D or 3D input. Computes \\\\\\\\\\\\\\\\y = \\\\\\\\frac{x - E\\\\\\\\\\\\\\\[x\\\\\\\\\\\\\\\]}{\\\\\\\\sqrt{Var\\\\\\\\\\\\\\\[x\\\\\\\\\\\\\\\]} + \\\\\\\\epsilon} \\\\\\\\gamma + \\\\\\\\beta,\\\\\\\\\\\\\\\\ where \\\\\\\\\\\\\\\\\\\\\\\\gamma\\\\\\\\\\\\\\\\ and \\\\\\\\\\\\\\\\\\\\\\\\beta\\\\\\\\\\\\\\\\ are learned per feature dimension parameters initialized at 1 and 0 respectively. The input shape is specified as \\\`\\\\\\\`NC\\\\\\\`\\\` or \\\`\\\\\\\`NLC\\\\\\\`\\\`, where \\\`\\\\\\\`N\\\\\\\`\\\` is the batch, \\\`\\\\\\\`C\\\\\\\`\\\` is the number of features or channels, and \\\`\\\\\\\`L\\\\\\\`\\\` is the sequence length. The output has the same shape as the input. For four-dimensional arrays, the shape is \\\`\\\\\\\`NHWC\\\\\\\`\\\`, where \\\`\\\\\\\`H\\\\\\\`\\\` and \\\`\\\\\\\`W\\\\\\\`\\\` are the height and width respectively. For more information on Batch Normalization, see the original paper \\\[Batch Normalization: Accelerating Deep Network Training by Reducing Internal Covariate Shift\\\](https://arxiv.org/abs/1502.03167). Parameters: - \\\\\\\*\\\\\\\*num\\\\\\\_features\\\\\\\*\\\\\\\* (\\\[\\\*int\\\*\\\](https://docs.python.org/3/library/functions.html#int "(in Python v3.13)")) – The feature dimension to normalize over. - \\\\\\\*\\\\\\\*eps\\\\\\\*\\\\\\\* (\\\[\\\*float\\\*\\\](https://docs.python.org/3/library/functions.html#float "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – A small additive constant for numerical stability. Default: \\\`\\\\\\\`1e-5\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*momentum\\\\\\\*\\\\\\\* (\\\[\\\*float\\\*\\\](https://docs.python.org/3/library/functions.html#float "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – The momentum for updating the running mean and variance. Default: \\\`\\\\\\\`0.1\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*affine\\\\\\\*\\\\\\\* (\\\[\\\*bool\\\*\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – If \\\`\\\\\\\`True\\\\\\\`\\\`, apply a learned affine transformation after the normalization. Default: \\\`\\\\\\\`True\\\\\\\`\\\`. - \\\\\\\*\\\\\\\*track\\\\\\\_running\\\\\\\_stats\\\\\\\*\\\\\\\* (\\\[\\\*bool\\\*\\\](https://docs.python.org/3/library/functions.html#bool "(in Python v3.13)")\\\\\\\*,\\\\\\\* \\\\\\\*optional\\\\\\\*) – If \\\`\\\\\\\`True\\\\\\\`\\\`, track the running mean and variance. Default: \\\`\\\\\\\`True\\\\\\\`\\\`. Examples \\\\>>> import mlx.core as mx >>> import mlx.nn as nn >>> x = mx.random.normal((5, 4)) >>> bn = nn.BatchNorm(num\\\\\\\_features=4, affine=True) >>> output = bn(x) Methods | | | |----|----| | \\\`\\\\\\\`unfreeze\\\\\\\`\\\`(\\\\\\\\\\\\\\\*args, \\\\\\\\\\\\\\\*\\\\\\\\\\\\\\\*kwargs) | Wrap unfreeze to make sure that running\\\\\\\_mean and var are always frozen parameters. | \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.AvgPool3d.html "previous page") previous mlx.nn.AvgPool3d \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/nn/\\\_autosummary/mlx.nn.CELU.html "next page") next mlx.nn.CELU Contents \\\\- \\\[\\\`\\\`BatchNorm\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.nn.BatchNorm) By MLX Contributors © Copyright 2023, MLX Contributors.
