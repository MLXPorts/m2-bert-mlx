Curator's note: Prefer the human-authored MLX guides for clarity. - ../docs\\\\\\\_curated/README.md - ../docs\\\\\\\_curated/PYTORCH\\\\\\\_DISSONANCE.md - ../docs\\\\\\\_curated/NUMPY\\\\\\\_USERS.md - ../docs\\\\\\\_curated/COMMON\\\\\\\_PITFALLS.md \\\[\\\](https://github.com/ml-explore/mlx "Source repository")\\\\- \\\[.rst\\\](https://ml-explore.github.io/mlx/build/html/\\\_sources/python/optimizers/optimizer.rst "Download source file") - .pdf # Optimizer ## Contents \\\\- \\\[\\\`\\\`Optimizer\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.optimizers.Optimizer) # Optimizer \\\\\\\*\\\`class\\\` \\\\\\\*\\\`Optimizer\\\`(\\\\\\\*\\\`schedulers\\\`\\\`\\\\=\\\`\\\`None\\\`\\\\\\\*) The base class for all optimizers. It allows us to implement an optimizer on a per-parameter basis and apply it to a parameter tree. Attributes | | | |----|----| | \\\[\\\`\\\`Optimizer.state\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/optimizers/\\\_autosummary/mlx.optimizers.Optimizer.state.html#mlx.optimizers.Optimizer.state "mlx.optimizers.Optimizer.state") | The optimizer's state dictionary. | Methods | | | |----|----| | \\\[\\\`\\\`Optimizer.apply\\\_gradients\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/optimizers/\\\_autosummary/mlx.optimizers.Optimizer.apply\\\_gradients.html#mlx.optimizers.Optimizer.apply\\\_gradients "mlx.optimizers.Optimizer.apply\\\_gradients")(gradients, parameters) | Apply the gradients to the parameters and return the updated parameters. | | \\\[\\\`\\\`Optimizer.init\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/optimizers/\\\_autosummary/mlx.optimizers.Optimizer.init.html#mlx.optimizers.Optimizer.init "mlx.optimizers.Optimizer.init")(parameters) | Initialize the optimizer's state | | \\\[\\\`\\\`Optimizer.update\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/python/optimizers/\\\_autosummary/mlx.optimizers.Optimizer.update.html#mlx.optimizers.Optimizer.update "mlx.optimizers.Optimizer.update")(model, gradients) | Apply the gradients to the parameters of the model and update the model with the new parameters. | \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/optimizers.html "previous page") previous Optimizers \\\[\\\](https://ml-explore.github.io/mlx/build/html/python/optimizers/\\\_autosummary/mlx.optimizers.Optimizer.state.html "next page") next mlx.optimizers.Optimizer.state Contents \\\\- \\\[\\\`\\\`Optimizer\\\`\\\`\\\](https://ml-explore.github.io/mlx/build/html/#mlx.optimizers.Optimizer) By MLX Contributors © Copyright 2023, MLX Contributors.
